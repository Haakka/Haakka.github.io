{"meta":{"title":"Hakka的个人博客","subtitle":"记录学习历程","description":"这是一个Java从业者的个人博客，内容不定看心情，学到啥写啥~想啥写啥~","author":"Hakka","url":"https://haakka.github.io","root":"/"},"pages":[{"title":"","date":"2019-03-23T07:54:13.000Z","updated":"2019-03-23T08:42:35.735Z","comments":true,"path":"404/index.html","permalink":"https://haakka.github.io/404/index.html","excerpt":"","text":"&lt;!DOCTYPE html&gt; 404"},{"title":"about","date":"2019-03-23T08:04:54.000Z","updated":"2019-03-23T08:04:54.112Z","comments":true,"path":"about/index.html","permalink":"https://haakka.github.io/about/index.html","excerpt":"","text":""},{"title":"categories","date":"2019-03-23T08:04:35.000Z","updated":"2019-03-23T08:04:35.635Z","comments":true,"path":"categories/index.html","permalink":"https://haakka.github.io/categories/index.html","excerpt":"","text":""},{"title":"tags","date":"2019-03-23T08:04:28.000Z","updated":"2019-03-23T08:04:28.551Z","comments":true,"path":"tags/index.html","permalink":"https://haakka.github.io/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"HashMap小结篇","slug":"HashMap","date":"2018-04-25T13:07:30.000Z","updated":"2019-03-31T13:50:16.395Z","comments":true,"path":"2018/04/25/HashMap/","link":"","permalink":"https://haakka.github.io/2018/04/25/HashMap/","excerpt":"","text":"名词解释：散列表（Hash table，又称哈希表），是根据关键码值(Key value)而直接进行访问的数据结构。也就是说，它通过把关键码值映射到表中一个位置来访问记录，以加快查找的速度。这个映射函数叫做散列函数，存放记录的数组叫做散列表。 Map(JDK文档)：An object that maps keys to values. A map cannot contain duplicate keys; each key can map to at most one value.（将键映射到值的对象。不能包含重复的键;每个键最多可以映射一个值。） HashMap概念HashMap 是一个散列表，它存储的内容是键值对(key-value)映射，继承于AbstractMap，实现了Map、Cloneable、java.io.Serializable接口。 1.Map 接口的实现提供所有可选的映射操作，并允许使用 null 值和 null 键。（除了不同步和允许使用 null 之外，HashMap 类与 Hashtable 大致相同。）此类不保证映射的顺序，特别是它不保证该顺序恒久不变。另外，HashMap是非线程安全的，也就是说在多线程的环境下，可能会存在问题，而Hashtable是线程安全的。 2.Map 接口的实现假定哈希函数将元素正确分布在各桶之间，可为基本操作（get 和 put）提供稳定的性能。迭代集合视图所需的时间与 HashMap 实例的“容量”（桶的数量）及其大小（键-值映射关系数）的和成比例。所以，如果迭代性能很重要，则不要将初始容量设置得太高（或将加载因子设置得太低）。 HashMap 的实例有两个参数影响其性能：初始容量 和 加载因子。 容量是哈希表中桶的数量，初始容量只是哈希表在创建时的容量。 加载因子是哈希表在其容量自动增加之前可以达到多满的一种尺度。 当哈希表中的条目数超出了加载因子与当前容量的乘积时，通过调用 rehash 方法将容量翻倍。通常，默认加载因子 (0.75) 在时间和空间成本上寻求一种折衷。加载因子过高虽然减少了空间开销，但同时也增加了查询成本（在大多数 HashMap 类的操作中，包括 get 和 put 操作，都反映了这一点）。所以在设置初始容量时应该考虑到映射中所需的条目数及其加载因子，以便最大限度地降低 rehash 操作次数。如果初始容量大于最大条目数乘以加载因子，则不会发生 rehash 操作。 Q：为什么需要使用加载因子，为什么需要扩容呢？加载因子为什么设置为0.75？A: 加载因子是表示Hsah表中元素的填满的程度，使用加载因子是因为如果一直不进行扩容的话，链表就会越来越长，这样查找的效率很低。加载因子越大,填满的元素越多,空间利用率越高，但冲突的机会加大了；反之,加载因子越小,填满的元素越少,冲突的机会减小,但空间浪费多了。冲突的机会越大,则查找的成本越高。在理想情况下,使用随机哈希码,节点出现的频率在hash桶中遵循泊松分布，当桶中元素到达8个的时候，概率已经变得非常小，也就是说用0.75作为加载因子，每个碰撞位置的链表长度超过8个是几乎不可能的。 HashMap结构JDK1.8之前，HashMap采用 数组 + 链表 实现，即使用链表处理冲突，同一hash值的节点都存储在一个链表里。但是当位于一个桶中的元素较多，即hash值相等的元素较多时，通过key值依次查找的效率较低。 JDK1.8之前 HashMap结构如上图JDK1.8中，HashMap采用数组+链表+红黑树实现，当链表长度超过阈值（8）时，将链表转换为红黑树。 JDK1.8 HashMap结构如上图 Q：JDK1.8中HashMap为什么要引入红黑树？A: 数组的优点是：物理地址连续 + 按下标随机访问效率高O(1)，缺点是插入，删除效率低；链表的优点是存储地址不连续，可灵活的扩展自己的长度，插入，删除效率高，但是访问效率低O(n)。所以当 HashMap 中有大量的元素都存放到同一个桶中时（Hash冲突），这个桶下有一条长长的链表，这个时候 HashMap 就相当于一个单链表，假如单链表有 n 个元素，遍历的时间复杂度就是 O(n)，而红黑树的时间复杂是O(logn)，大大的提高了查找速度。 Q：JDK1.8中HashMap为什么当链表长度大于8时才转换成红黑树呢？A: 因为红黑树的时间复杂是O(logn），长度为8的时候，平均查找长度为3。如果继续使用链表，平均查找长度为8/2=4。这才有转换为树的必要。。链表长度如果是6以内，6/2=3，速度也很快的。转化为树还有生成树的时间，并不明智。长度为8，链表转树，长度为6，树转链表，中间有个差值，可以防止链表和树频繁转换。假设8以上转为树，8以下转为链表，那么Hashmap如果不停的插入删除，链表长度在8左右徘徊，就会不停的树转链表，链表转树，就会效率很低。 JDK1.8 HashMap源码分析HashMap的数据存储流程： 根据key计算得到key.hash = (h = k.hashCode()) ^ (h &gt;&gt;&gt; 16)； 根据key.hash计算得到桶数组的索引index = key.hash &amp; (table.length - 1)，这样就找到该key的存放位置了： 如果该位置没有数据，用该数据新生成一个节点保存新数据，返回null； 如果该位置有数据是一个红黑树，那么执行相应的插入 / 更新操作； 如果该位置有数据是一个链表，分两种情况一是该链表没有这个节点，另一个是该链表上有这个节点，注意这里判断的依据是key.hash是否一样，如果该链表没有这个节点，那么采用尾插法新增节点保存新数据，返回null；如果该链表已经有这个节点了，那么找到该节点并更新新数据，返回老数据。 注意：HashMap的put会返回key的上一次保存的数据。 JDK1.8 HashMap中的主要属性字段1234567891011121314151617181920212223242526// 序列号private static final long serialVersionUID = 362498820763181265L; // 默认的初始容量是16static final int DEFAULT_INITIAL_CAPACITY = 1 &lt;&lt; 4; // 最大容量static final int MAXIMUM_CAPACITY = 1 &lt;&lt; 30;// 默认的填充因子static final float DEFAULT_LOAD_FACTOR = 0.75f;// 当桶(bucket)上的结点数大于这个值时会转成红黑树static final int TREEIFY_THRESHOLD = 8;// 当桶(bucket)上的结点数小于这个值时树转链表static final int UNTREEIFY_THRESHOLD = 6;// 桶中结构转化为红黑树对应的table的最小大小static final int MIN_TREEIFY_CAPACITY = 64;// 存储元素的数组，总是2的幂次倍transient Node&lt;k,v&gt;[] table;// 存放具体元素的集transient Set&lt;map.entry&lt;k,v&gt;&gt; entrySet;// 存放元素的个数，注意这个不等于数组的长度。transient int size;// 每次扩容和更改map结构的计数器transient int modCount; // 临界值 当实际大小(容量*填充因子)超过临界值时，会进行扩容int threshold;// 填充因子final float loadFactor; 存储方法putVal() put() 和 putVal()源码123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778public V put(K key, V value) &#123; // 对key的hashCode()做hash return putVal(hash(key), key, value, false, true); &#125;final V putVal(int hash, K key, V value, boolean onlyIfAbsent, boolean evict) &#123; Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; p; int n, i; // 步骤1：判断当前桶是否为空，空的就需要初始化（resize 中会判断是否进行初始化） if ((tab = table) == null || (n = tab.length) == 0) n = (tab = resize()).length; // 步骤2：计算index，并对null做处理 // (n - 1) &amp; hash 确定元素存放在哪个桶中，定位到具体的桶中并判断是否为空，为空表明没有Hash冲突就直接在当前位置创建一个新桶即可 if ((p = tab[i = (n - 1) &amp; hash]) == null) tab[i] = newNode(hash, key, value, null); // 桶中已经存在元素 else &#123; Node&lt;K,V&gt; e; K k; // 步骤3：节点key存在，直接覆盖value // 如果当前桶有值（Hash冲突），那么就要比较当前桶中的key、key的hashcode与写入的key是否相等，相等就赋值给 e if (p.hash == hash &amp;&amp; ((k = p.key) == key || (key != null &amp;&amp; key.equals(k)))) // 将第一个元素赋值给e，用e来记录 e = p; // 步骤4：判断该链为红黑树 // 如果当前桶为红黑树，那就要按照红黑树的方式写入数据 else if (p instanceof TreeNode) // 放入树中 e = ((TreeNode&lt;K,V&gt;)p).putTreeVal(this, tab, hash, key, value); // 步骤5：该链为链表 // 为链表结点 else &#123; // 如果是个链表，就需要将当前的 key、value 封装成一个新节点写入到当前桶的后面（形成链表） for (int binCount = 0; ; ++binCount) &#123; // 到达链表的尾部 if ((e = p.next) == null) &#123; // 在尾部插入新结点 p.next = newNode(hash, key, value, null); // 判断当前链表的大小是否大于预设的阈值，大于时就要转换为红黑树 if (binCount &gt;= TREEIFY_THRESHOLD - 1) // -1 for 1st treeifyBin(tab, hash); // 跳出循环 break; &#125; // 判断链表中结点的key值与插入的元素的key值是否相等 if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) // 相等，跳出循环 break; // 用于遍历桶中的链表，与前面的e = p.next组合，可以遍历链表 p = e; &#125; &#125; // 表示在桶中找到key值、hash值与插入元素相等的结点 if (e != null) &#123; // 记录e的value V oldValue = e.value; // onlyIfAbsent为false或者旧值为null if (!onlyIfAbsent || oldValue == null) //用新值替换旧值 e.value = value; // 访问后回调 afterNodeAccess(e); // 返回旧值 return oldValue; &#125; &#125; // 结构性修改 ++modCount; // 步骤6：超过最大容量 就扩容 // 实际大小大于阈值则扩容 if (++size &gt; threshold) resize(); // 插入后回调 afterNodeInsertion(evict); return null;&#125; 步骤 判断键值对数组table[i]是否为空或为null，否则执行resize()进行扩容； 根据键值key计算hash值得到插入的数组索引i，如果table[i]==null，直接新建节点添加，转向⑥，如果table[i]不为空，转向③； 判断table[i]的首个元素是否和key一样，如果相同直接覆盖value，否则转向④，这里的相同指的是hashCode以及equals； 判断table[i] 是否为treeNode，即table[i] 是否是红黑树，如果是红黑树，则直接在树中插入键值对，否则转向⑤； 遍历table[i]，判断链表长度是否大于8，大于8的话把链表转换为红黑树，在红黑树中执行插入操作，否则进行链表的插入操作；遍历过程中若发现key已经存在直接覆盖value即可； 插入成功后，判断实际存在的键值对数量size是否超多了最大容量threshold，如果超过，进行扩容。 hash()方法首先获取对象的hashCode()值，然后将hashCode值右移16位，然后将右移后的值与原来的hashCode做异或运算，返回结果。其中h&gt;&gt;&gt;16，在JDK1.8中，优化了高位运算的算法，使用了零扩展，无论正数还是负数，都在高位插入0。1234static final int hash(Object key) &#123; int h; return (key == null) ? 0 : (h = key.hashCode()) ^ (h &gt;&gt;&gt; 16);&#125; get() 和 getNode()方法12345678910111213141516171819202122232425262728293031public V get(Object key) &#123; Node&lt;k,v&gt; e; return (e = getNode(hash(key), key)) == null ? null : e.value;&#125;final Node&lt;K,V&gt; getNode(int hash, Object key) &#123; Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; first, e; int n; K k; // table已经初始化，长度大于0，根据hash寻找table中的项也不为空 if ((tab = table) != null &amp;&amp; (n = tab.length) &gt; 0 &amp;&amp; (first = tab[(n - 1) &amp; hash]) != null) &#123; // 判断桶的第一个位置(有可能是链表、红黑树)的 key 是否为查询的 key，是就直接返回 value if (first.hash == hash &amp;&amp; ((k = first.key) == key || (key != null &amp;&amp; key.equals(k)))) return first; // 如果第一个不匹配，则判断它的下一个是红黑树还是链表 if ((e = first.next) != null) &#123; // 为红黑树结点 if (first instanceof TreeNode) // 按照树的查找方式返回值 return ((TreeNode&lt;K,V&gt;)first).getTreeNode(hash, key); // 否则，在链表中查找遍历匹配并返回值 do &#123; if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) return e; &#125; while ((e = e.next) != null); &#125; &#125; return null;&#125; 扩容方法resize() 在jdk1.8中，resize方法是在hashmap中的键值对大于阀值时或者初始化时，就调用resize方法进行扩容； 每次扩展的时候，都是扩展2倍； 扩展后Node对象的位置要么在原位置，要么移动到原偏移量两倍的位置。 resize()源码分析123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105final Node&lt;K,V&gt;[] resize() &#123; //oldTab指向hash桶数组 Node&lt;K,V&gt;[] oldTab = table; //旧表的长度 int oldCap = (oldTab == null) ? 0 : oldTab.length; int oldThr = threshold; int newCap, newThr = 0; //如果oldCap不为空的话，就是hash桶数组不为空 if (oldCap &gt; 0) &#123; //如果大于最大容量了，就赋值为整数最大的阀值 if (oldCap &gt;= MAXIMUM_CAPACITY) &#123; threshold = Integer.MAX_VALUE; return oldTab; &#125; //如果当前hash桶数组的长度在扩容后仍然小于最大容量 并且oldCap大于默认值16 else if ((newCap = oldCap &lt;&lt; 1) &lt; MAXIMUM_CAPACITY &amp;&amp; oldCap &gt;= DEFAULT_INITIAL_CAPACITY) // double threshold 双倍扩容阀值 newThr = oldThr &lt;&lt; 1; &#125; else if (oldThr &gt; 0) //初始容量被置于阈值 newCap = oldThr; else &#123; // 零初始阈值表示使用默认值 newCap = DEFAULT_INITIAL_CAPACITY; newThr = (int)(DEFAULT_LOAD_FACTOR * DEFAULT_INITIAL_CAPACITY); &#125; if (newThr == 0) &#123; //新表长度乘以加载因子 float ft = (float)newCap * loadFactor; newThr = (newCap &lt; MAXIMUM_CAPACITY &amp;&amp; ft &lt; (float)MAXIMUM_CAPACITY ? (int)ft : Integer.MAX_VALUE); &#125; threshold = newThr; @SuppressWarnings(&#123;\"rawtypes\",\"unchecked\"&#125;) Node&lt;K,V&gt;[] newTab = (Node&lt;K,V&gt;[])new Node[newCap];//新建hash桶数组 //将新数组的值复制给旧的hash桶数组 table = newTab; ////进行扩容操作，复制Node对象值到新的hash桶数组 if (oldTab != null) &#123; //遍历旧表数据 for (int j = 0; j &lt; oldCap; ++j) &#123; Node&lt;K,V&gt; e; //如果旧的hash桶数组在j结点处不为空，复制给e if ((e = oldTab[j]) != null) &#123; //将旧的hash桶数组在j结点处设置为空，方便gc oldTab[j] = null; //如果e后面没有Node结点 if (e.next == null) //直接对e的hash值对新的数组长度求模获得存储位置 newTab[e.hash &amp; (newCap - 1)] = e; else if (e instanceof TreeNode) //如果e是红黑树的类型，那么添加到红黑树中 ((TreeNode&lt;K,V&gt;)e).split(this, newTab, j, oldCap); else &#123; // 保证顺序 Node&lt;K,V&gt; loHead = null, loTail = null; Node&lt;K,V&gt; hiHead = null, hiTail = null; Node&lt;K,V&gt; next; do &#123; //记录下一个结点 next = e.next; //如果结点e的hash值与原hash桶数组的长度作与运算为0 if ((e.hash &amp; oldCap) == 0) //如果loTail为null &#123; if (loTail == null) //将e结点赋值给loHead loHead = e; else //否则将e赋值给loTail.next loTail.next = e; //然后将e复制给loTail loTail = e; &#125; else &#123; //如果hiTail为null if (hiTail == null) //将e赋值给hiHead hiHead = e; else //如果hiTail不为空，将e复制给hiTail.next hiTail.next = e; //将e复制个hiTail hiTail = e; &#125; &#125; while ((e = next) != null);//直到e为空 //如果loTail不为空 if (loTail != null) &#123; //将loTail.next设置为空 loTail.next = null; //将loHead赋值给新的hash桶数组[j]处 newTab[j] = loHead; &#125; //如果hiTail不为空 if (hiTail != null) &#123; //将hiTail.next赋值为空 hiTail.next = null; //将hiHead赋值给新的hash桶数组[j+旧hash桶数组长度] newTab[j + oldCap] = hiHead; &#125; &#125; &#125; &#125; &#125; return newTab;&#125; JDK1.7 HashMap源码分析JDK1.7 HashMap中的主要属性字段1234567891011121314151617181920212223// 初始桶大小，因为底层是数组，所以这是数组的大小static final int DEFAULT_INITIAL_CAPACITY = 1 &lt;&lt; 4; // aka 16// 桶最大值static final int MAXIMUM_CAPACITY = 1 &lt;&lt; 30;// 默认的负载因子static final float DEFAULT_LOAD_FACTOR = 0.75f;// 未扩容时的空表实例static final Entry&lt;?,?&gt;[] EMPTY_TABLE = &#123;&#125;;// 真正存放数据的数组transient Entry&lt;K,V&gt;[] table = (Entry&lt;K,V&gt;[]) EMPTY_TABLE;// Map存放数量的大小transient int size;// 桶大小，可在初始化时显式指定int threshold;// 负载因子，可在初始化时显式指定final float loadFactor; Entry类主要结构方法12345678910111213141516171819202122232425static class Entry&lt;K,V&gt; implements Map.Entry&lt;K,V&gt; &#123; //key是写入的键 final K key; //value是key对应的值 V value; //next用于实现链表结构，指向下一个链表节点 Entry&lt;K,V&gt; next; //hash存放的是当前key的hashCode int hash; Entry(int h, K k, V v, Entry&lt;K,V&gt; n) &#123; value = v; next = n; key = k; hash = h; &#125; public final K getKey() &#123; return key; &#125; public final V getValue() &#123; return value; &#125;&#125; hash()函数1234567891011121314final int hash(Object k) &#123; int h = 0; if (useAltHashing) &#123; if (k instanceof String) &#123; return sun.misc.Hashing.stringHash32((String) k); &#125; h = hashSeed; &#125; h ^= k.hashCode(); h ^= (h &gt;&gt;&gt; 20) ^ (h &gt;&gt;&gt; 12); return h ^ (h &gt;&gt;&gt; 7) ^ (h &gt;&gt;&gt; 4); &#125; put()函数首先判断table 是否为空或者null ,如果是，进行resize扩容,如果 key = null，这个key防止entry数组的 table[0]，如果key !=null 计算key的hash 值， 然后根据hash值 找到数据的下标。遍历这个数组下的链表，如果链表下有相同的key值，用这个新节点Node(K,V)的V 替代原来旧的value，如果链表下没有相同的key,在链表中增加， 如果size&gt;threadhold 时候，进行扩容，此时需要根据hash重新计算数组下标，最后将节点加入到链表的表头，方便查找。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970public V put(K key, V value) &#123; // 当插入第一个元素的时候，需要先初始化数组大小 if (table == EMPTY_TABLE) &#123; //初始化 inflateTable(threshold); &#125; // 如果 key 为 null，会将这个 entry 放到 table[0] 中 if (key == null) return putForNullKey(value); // 1. 求 key 的 hash 值 int hash = hash(key); // 2. 找到对应的数组下标 int i = indexFor(hash, table.length); // 3. 遍历一下对应下标处的链表，看是否有重复的 key 已经存在， // 如果有，直接覆盖，put 方法返回旧值就结束了 for (Entry&lt;K,V&gt; e = table[i]; e != null; e = e.next) &#123; Object k; if (e.hash == hash &amp;&amp; ((k = e.key) == key || key.equals(k))) &#123; V oldValue = e.value; e.value = value; e.recordAccess(this); return oldValue; &#125; &#125; modCount++; // 4. 不存在重复的 key，将此 entry 添加到链表中，细节后面说 addEntry(hash, key, value, i); return null;&#125;private void inflateTable(int toSize) &#123; // 保证数组大小一定是 2 的 n 次方。 // 比如这样初始化：new HashMap(20)，那么处理成初始数组大小是 32 int capacity = roundUpToPowerOf2(toSize); // 计算扩容阈值：capacity * loadFactor threshold = (int) Math.min(capacity * loadFactor, MAXIMUM_CAPACITY + 1); // 算是初始化数组吧 table = new Entry[capacity]; initHashSeedAsNeeded(capacity); //ignore&#125;/** * 使用 key的hash值对数组长度进行取模 */static int indexFor(int hash, int length) &#123; // assert Integer.bitCount(length) == 1 : \"length must be a non-zero power of 2\"; return hash &amp; (length-1);&#125;void addEntry(int hash, K key, V value, int bucketIndex) &#123; // 如果当前 HashMap 大小已经达到了阈值，并且新值要插入的数组位置已经有元素了，那么要扩容 if ((size &gt;= threshold) &amp;&amp; (null != table[bucketIndex])) &#123; // 如果需要就进行两倍扩充，并将当前的 key 重新 hash 并定位 resize(2 * table.length); // 扩容以后，重新计算 hash 值 hash = (null != key) ? hash(key) : 0; // 重新计算扩容后的新的下标 bucketIndex = indexFor(hash, table.length); &#125; // 往下看 createEntry(hash, key, value, bucketIndex);&#125; // 新值放到链表的表头，然后 size++ void createEntry(int hash, K key, V value, int bucketIndex) &#123; Entry&lt;K,V&gt; e = table[bucketIndex]; table[bucketIndex] = new Entry&lt;&gt;(hash, key, value, e); size++; &#125; get()函数根据 key 计算 hash 值，如果key=null 返回的是tabe[0]的链表，如果key!=null key做hash，找到相应的数组下标，遍历该数组位置处的链表，直到找到相等(==或equals)的key，找到对应Node值，然后返回。1234567891011121314151617181920212223242526272829public V get(Object key) &#123; // 之前说过，key 为 null 的话，会被放到 table[0]，所以只要遍历下 table[0] 处的链表就可以了 if (key == null) return getForNullKey(); // Entry&lt;K,V&gt; entry = getEntry(key); return null == entry ? null : entry.getValue();&#125;final Entry&lt;K,V&gt; getEntry(Object key) &#123; if (size == 0) &#123; return null; &#125; // 根据 key 计算出 hashcode，然后定位到具体的桶中 int hash = (key == null) ? 0 : hash(key); // 确定数组下标，然后从头开始遍历链表，直到找到为止 for (Entry&lt;K,V&gt; e = table[indexFor(hash, table.length)]; e != null; e = e.next) &#123; Object k; // 根据 key、key 的 hashcode 是否相等来返回值 if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) return e; &#125; // 没取到就直接返回 null return null;&#125; resize()函数12345678910111213141516171819202122232425262728293031323334353637383940414243void resize(int newCapacity) &#123; Entry[] oldTable = table; //旧桶长度 int oldCapacity = oldTable.length; //判断是否到达桶的最大值 if (oldCapacity == MAXIMUM_CAPACITY) &#123; threshold = Integer.MAX_VALUE; return; &#125; // 新的数组 Entry[] newTable = new Entry[newCapacity]; // 将原来数组中的值迁移到新的更大的数组中 transfer(newTable, initHashSeedAsNeeded(newCapacity)); table = newTable; threshold = (int)Math.min(newCapacity * loadFactor, MAXIMUM_CAPACITY + 1);&#125;void transfer(Entry[] newTable) &#123; //src引用了旧的Entry数组 Entry[] src = table; int newCapacity = newTable.length; //遍历旧的Entry数组 for (int j = 0; j &lt; src.length; j++) &#123; //取得旧Entry数组的每个元素 Entry&lt;K,V&gt; e = src[j]; if (e != null) &#123; //释放旧Entry数组的对象引用（for循环后，旧的Entry数组不再引用任何对象） src[j] = null; do &#123; // 头插法建立链表 Entry&lt;K,V&gt; next = e.next; //重新计算每个元素在数组中的位置 int i = indexFor(e.hash, newCapacity); //标记[1] e.next = newTable[i]; //将元素放在数组上 newTable[i] = e; //访问下一个Entry链上的元素 e = next; &#125; while (e != null); &#125; &#125; &#125; 扩展阅读 JDK1.7中HashMap的死循环解读 JDK1.7 HashMap扩容：多线程下的死循环和丢失 HashMap中的为什么hash的长度为2的幂而&amp;位必须为奇数","categories":[],"tags":[{"name":"HashMap","slug":"HashMap","permalink":"https://haakka.github.io/tags/HashMap/"}]},{"title":"Hello World","slug":"hello-world","date":"2018-02-18T02:35:16.000Z","updated":"2019-03-25T12:08:52.522Z","comments":true,"path":"2018/02/18/hello-world/","link":"","permalink":"https://haakka.github.io/2018/02/18/hello-world/","excerpt":"","text":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new \"My New Post\" More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment","categories":[],"tags":[]},{"title":"第一篇文章测试","slug":"First","date":"2018-02-17T04:35:16.000Z","updated":"2019-03-25T12:08:54.333Z","comments":true,"path":"2018/02/17/First/","link":"","permalink":"https://haakka.github.io/2018/02/17/First/","excerpt":"","text":"写作介绍1，字体介绍这是斜体 或 这也是斜体这是粗体这是加粗斜体这是删除线 2，分级标题一级标题二级标题三级标题四级标题五级标题六级标题3，超链接写法： 行内形式：我的博客参考形式：[我的博客][1]，有一个很好的平台-[简书][2][1]:https://Haakka.github.io/自动链接：我的博客地址https://Haakka.github.io/ 4,列表无序列表：写法： 无序列表项1 无序列表项2 无序列表项3s有序列表：写法：1.有序列表项12.有序列表项23.有序列表项3 5，插入图片在 Hexo 中插入图片，需要将图片放在 source/img/ 文件夹下 6，表格 表头1 表头2 表头3 表头4 默认左对齐 左对齐 居中对其 右对齐 默认左对齐 左对齐 居中对其 右对齐 默认左对齐 左对齐 居中对其 右对齐","categories":[],"tags":[{"name":"test","slug":"test","permalink":"https://haakka.github.io/tags/test/"}]}]}